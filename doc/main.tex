\documentclass[12pt]{article}

\usepackage{underscore}
\usepackage{rka-style}

\usepackage[margin=0.875in]{geometry}
\usepackage{accents, hyperref, chngcntr, tikz-cd}
\usepackage[linesnumbered, noline]{algorithm2e}
\usepackage{natbib}
\bibliographystyle{plainnat}
\setcitestyle{authoryear,round,citesep={;},aysep={,},yysep={;}}

\hypersetup{ %
    pdfborder=0 0 0,
    pdfpagemode=UseNone,
    colorlinks=true,
    linkcolor=blue,
    citecolor=blue,
    filecolor=blue,
    urlcolor=blue,
    pdfview=FitH}

\usepackage{cleveref,booktabs}

% TO DO NOTES
\usepackage[colorinlistoftodos,bordercolor=orange,backgroundcolor=orange!20,linecolor=orange,textsize=scriptsize]{todonotes}
\newcommand{\sra}[1]{\todo[inline]{{\textbf{Sara:} \emph{#1}}}}
\newcommand{\ahmed}[1]{\todo[inline]{{\textbf{Ahmed:} \emph{#1}}}}

% Preamble End
% Document Start

\begin{document}

\title{Big Data Project Report}
\author{Ahmed Essam, Ahmed Khaled, Sara Maher, Ibrahim Mahmoud}

\maketitle

\abstract{This report gives a time series analysis of historical Walmart sales data about more than three thousand different products sold across three different states in the United States. The data is part of the M5 forecasting competition \citep{Makridakis2020} and in addition to the time series analysis we also propose and describe a forecasting system and analyze its prediction capabilities.}

\tableofcontents
\clearpage
\section{Introduction}
Sales forecasting is important because bla bla

\subsection{Problem Definition}
We are given Walmart sales data from ten stores in three different states. Our project can be divided into two main problems: the first is to answer business-related questions on the dataset (data analysis) and the second is to devise a machine learning model that can predict the sales of each item offered by the stores twenty eight days into the future. 

This document is organized as follows: we review the dataset next, perform exploratory data analysis in the succeeding section, and outline our efforts at developing a forecasting model (and its evaluation) in the last section.

\subsection{Dataset Overview}
The dataset is given by the \emph{M5 competition} available on Kaggle\footnote{\url{https://www.kaggle.com/c/m5-forecasting-accuracy}.} which is the current installment in the popular M competition series on forecasting \citep{Makridakis2020}. The dataset includes time series data of the sales of various Walmart store products divided hierarchically by the item level, department, product category, and geographical area. The dataset also includes explanatory variables such as price, promotions, day of the week, and special events (e.g. Valentine's Day, Orthodox Easter, and the Super Bowl, one of the largest sporting events in American Football). There are $3,075$ products classified in $3$ product categories and $7$ product departments. The products are sold across $10$ stores in $3$ different states (California, Texas, and Wisconsin). The total number of M5 series across the entire hierarchy is $42,840$.  The dataset guide is given on the \href{https://mk0mcompetitiont8ake.kinstacdn.com/wp-content/uploads/2020/02/M5-Competitors-Guide_Final-1.pdf}{on the M5 competition website}.

\clearpage
\section{Data Analysis}
\subsection{Dataset Files}
The dataset is divided into four files, each of which is described in \Cref{tab:dataset-desc}.

\begin{table}[h]
    \centering
    \caption{Dataset description}
    \label{tab:dataset-desc}
    \begin{tabular}{@{}ccc@{}}
    \toprule
    File name                  & Description                                                                                                & Shape               \\ \midrule
    sales_train_validation.csv & Contains the sales data for each item                                                                      & $30490 \times 1919$ \\
    calendar.csv & \begin{tabular}[c]{@{}c@{}}Contains calendar dates as well as \\ any events that happen on each date.\end{tabular} & $1969 \times 14$ \\
    sell_prices.csv            & \begin{tabular}[c]{@{}c@{}}Contains the sell price for each item\\ divided by store and week.\end{tabular} & $6841121 \times 4$  \\
    sample_submission.csv      & \begin{tabular}[c]{@{}c@{}}Contains sample submission forecasting\\ for the competition.\end{tabular}      & $60980 \times 29$   \\ \bottomrule
    \end{tabular}
\end{table}

The columns in each file are described in \Cref{tab:calendar-desc}.

% Please add the following required packages to your document preamble:
% \usepackage{booktabs}
\begin{table}[]
    \centering
    \caption{calendar.csv columns description. Note that SNAP stands for 
    Supplemental Nutrition Assistance Program, a program to help provide food for low-income families in the United States of America.}
    \label{tab:calendar-desc}
    \begin{tabular}{@{}cc@{}}
    \toprule
    Column Name                                                       & Description                         \\ \midrule
    Date                                                              & The full date as a string.          \\
    wm_yr_wk                                                          & Week id.                            \\
    \begin{tabular}[c]{@{}c@{}}weekday/wday\\ month/year\end{tabular} & Date split up.                      \\
    event_name_1/2                                                    & Name of this event (if applicable). \\
    event_type_1/2                                                    & Type of the event (if applicable).  \\
    \begin{tabular}[c]{@{}c@{}}snap_CA\\ snap_TX\\ snap_WI\end{tabular} & \begin{tabular}[c]{@{}c@{}}Indicator of whether the stores allow\\ SNAP purchases.\end{tabular} \\ \bottomrule
    \end{tabular}
\end{table}



\clearpage
\section{Forecasting}

\clearpage
\bibliography{main}

\clearpage
\section{Goals}
Draft of the analysis points we should cover, divided into 3 states: done, doing, and haven't started. Will be updated with more points, if we think of more, and the current state of each one. This is just a draft to do list and will surely be replaced in the final document.
\begin{enumerate}
    \item total sold items in each store
    \item total sold items in each state
    \item total sold items of each category
    \item total sold items of each category given the state
    \item total sold items of each category given the store
    \item total sold items of each category given an event happens in that day
    \item total sold items of each department
    \item total sold items of each department given the state
    \item total sold items of each department given the store
    \item total sold items of each department given an event happens in that day
    \item total sold items in each weekday
    \item total sold items in each month
    \item total revenue in each store
    \item total revenue in each state
    \item total revenue of each category
    \item total revenue of each category given the state
    \item total revenue of each category given the store
    \item total revenue of each category given an event happens in that day
    \item total revenue in each weekday
    \item total revenue in each month
    \item total revenue in each year
\end{enumerate}

Interesting questions that our project should answer:
\begin{enumerate}
    \item Which department is the most important by sales? Which department is the least important?
    \item Which items are commonly bought together in each store? What about which items are bought together in each state?
    \item Which feast days generate the most sales? Which feast days generate the least?
    \item Which items are the most profitable (i.e. best revenue*nsales)? Where are these sold?
    \item Can we predict the item sales accurately?
\end{enumerate}

\end{document}

\clearpage
\section{Proposal}
\ahmed{Will probably remove this later.}
\subsection{Idea}
We want to forecast the unit sales of different products sold by Walmart markets in the United States. More precisely, given hierarchical sales data from Walmart we will forecast daily sales for two subsequent 28-day time periods.

\subsection{Planned Approach}
We aim to use a mix of statistical features specific to time series data combined with neural networks. For deseasonalization we can use techniques like exponential smoothing or other statistical procedures on sliding windows. We hope to understand the seasonality patterns in the data first and then use a recurrent neural network to predict the trends.


